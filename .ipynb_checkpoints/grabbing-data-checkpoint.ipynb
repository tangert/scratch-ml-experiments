{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pprint\n",
    "import collections\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pynpm import NPMPackage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_blocks(blocks):\n",
    "    return {bid: block for bid,block in blocks.items() if 'topLevel' in list(block) and block['topLevel']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_stack_sequence(all_blocks, tid):\n",
    "    \"\"\" builds a sequential stack sequence \"\"\"\n",
    "    stack = []\n",
    "    curr_id = tid\n",
    "    stack.append(all_blocks[curr_id]['opcode'])\n",
    "    while curr_id is not None:\n",
    "        curr_id = all_blocks[curr_id]['next']\n",
    "        if curr_id != None:\n",
    "            stack.append(all_blocks[curr_id]['opcode'])\n",
    "    return stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rnn_sequences(stack, seq_len):\n",
    "    \"\"\"\n",
    "    produces a list of rnn-ready sequences given an input stack sequence\n",
    "    iterates through\n",
    "    \"\"\"\n",
    "    seqs = []\n",
    "    for i in range(seq_len):\n",
    "        seq = stack[i:seq_len]\n",
    "        if(len(seq)<seq_len):\n",
    "            seq.extend([None] * (seq_len - len(seq)))\n",
    "        if(not all(el is None for el in seq)):\n",
    "            seqs.append(seq)\n",
    "    return seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_terminal_blocks(blocks):\n",
    "    return { k:blocks[k] for k in blocks\n",
    "             if type(blocks[k]) is dict # prevents stop blocks\n",
    "             if blocks[k]['next'] is None # nothing after it\n",
    "             if not blocks[k]['shadow'] # not a shadow block\n",
    "             if 'operator' not in blocks[k]['opcode'] # not an operator\n",
    "             if 'SUBSTACK' not in blocks[k]['inputs'] # has no children\n",
    "             if 'SUBSTACK2' not in blocks[k]['inputs'] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_blocks(blocks):\n",
    "    return { k:blocks[k] for k in blocks \n",
    "            if type(blocks[k]) is dict # prevents stop blocks\n",
    "            if 'operator' not in blocks[k]['opcode'] # prevents operators\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paths(blks):\n",
    "    \"\"\" returns all of the paths from top->terminal block of a sprite \"\"\"\n",
    "    paths = []\n",
    "    blks = filter_blocks(blks)\n",
    "    \n",
    "    # symbols for direction in the tree\n",
    "    _nest = '>'\n",
    "    _next = '_'\n",
    "    \n",
    "    terminals = get_terminal_blocks(blks)\n",
    "\n",
    "    for t in terminals:\n",
    "\n",
    "        # initialize the path ending with the terminal\n",
    "\n",
    "        curr_parent_id = t\n",
    "        curr_parent = blks[curr_parent_id]\n",
    "        next_parent_id = terminals[t]['parent']\n",
    "        path = [curr_parent['opcode']]\n",
    "        \n",
    "        should_dump = False\n",
    "        \n",
    "        if next_parent_id is not None and next_parent_id in blks:\n",
    "            \n",
    "            next_parent = blks[next_parent_id]\n",
    "            \n",
    "            if t == next_parent['next']:\n",
    "                path.insert(0,_next)\n",
    "            else:\n",
    "                path.insert(0,_nest)\n",
    "\n",
    "            # initializie before traverseing\n",
    "            path.insert(0,next_parent['opcode'])\n",
    "\n",
    "            # begin the traversal with the next parent\n",
    "            curr_parent_id = next_parent_id\n",
    "\n",
    "            # go up the tree\n",
    "            while True:\n",
    "                # set the current parent to its own parent\n",
    "\n",
    "                # in order to determine nesting / sequence,\n",
    "                # if the current block id is the same as its parent's next\n",
    "                # then it's next\n",
    "                #  if it's not, then it's nested\n",
    "                next_parent_id = blks[curr_parent_id]['parent']\n",
    "                \n",
    "                if next_parent_id is not None and next_parent_id in blks:\n",
    "                    \n",
    "                        curr_parent = blks[curr_parent_id]\n",
    "                        next_parent = blks[next_parent_id]\n",
    "\n",
    "                        if curr_parent_id == next_parent['next']:\n",
    "                            path.insert(0,_next)\n",
    "                        else:\n",
    "                            path.insert(0,_nest)\n",
    "\n",
    "                        path.insert(0,next_parent['opcode'])\n",
    "\n",
    "                        # reset for the next iteration\n",
    "                        curr_parent_id = next_parent_id\n",
    "    \n",
    "                else:\n",
    "                    break\n",
    "                    \n",
    "            if not should_dump:\n",
    "                paths.append(path)\n",
    "            else:\n",
    "                continue\n",
    "    \n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id_df = pd.read_csv('data/project-ids/project_ids_train_1000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_ids = list(project_id_df['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_projects(project_ids):\n",
    "    for pid in project_ids:\n",
    "        proj_url = 'https://projects.scratch.mit.edu/{}'.format(pid)\n",
    "        r = requests.get(url = proj_url, params = {}) \n",
    "        proj_data = r.json()\n",
    "        with open('data/project-json/{}.json'.format(pid), 'w') as outfile:\n",
    "            json.dump(proj_data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sequences(sequence_length):\n",
    "    print('what')\n",
    "    all_sequences = []\n",
    "\n",
    "    for pid in project_ids:\n",
    "        # sending get request and saving the response as response object \n",
    "        proj_path = 'data/project-json/{}.json'.format(pid)\n",
    "\n",
    "        # load the pre-downloaded project json data\n",
    "        with open(proj_path) as f:\n",
    "\n",
    "            proj_data = json.load(f)\n",
    "            sprites = proj_data['targets'][1:] \n",
    "\n",
    "            for s in sprites:\n",
    "                all_blocks = s['blocks']\n",
    "                paths = get_paths(all_blocks)\n",
    "                \n",
    "                # filter out any lone soliders if necessary\n",
    "                paths = [p for p in paths if len(p) > 1]\n",
    "                all_sequences.extend(paths)\n",
    "    return all_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def old_sequences():\n",
    "    for pid in project_ids:\n",
    "        # sending get request and saving the response as response object \n",
    "        proj_path = 'data/project-json/{}.json'.format(pid)\n",
    "\n",
    "        # load the pre-downloaded project json data\n",
    "        with open(proj_path) as f:\n",
    "\n",
    "            proj_data = json.load(f)\n",
    "            sprites = proj_data['targets'][1:] \n",
    "\n",
    "            for s in sprites:\n",
    "                all_blocks = s['blocks']\n",
    "                tops = get_top_blocks(all_blocks)\n",
    "                topids = [bid for bid,block in tops.items()]\n",
    "                for tid in topids:\n",
    "                    s = build_stack_sequence(all_blocks, tid)\n",
    "                    #Only build sequences out of stacks with at least two blocks\n",
    "                    if(len(s) > 1):\n",
    "                        seqs = build_rnn_sequences(s,sequence_length)\n",
    "                        all_sequences.extend(seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reject_outliers(data, m=2):\n",
    "    return data[abs(np.array(data) - np.mean(data)) < m * np.std(data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what\n"
     ]
    }
   ],
   "source": [
    "all_seqs = make_sequences(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = [len(sub) for sub in all_seqs]\n",
    "mean = np.mean(lengths)\n",
    "std = np.std(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.37940212275634"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.506860211198592"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_seqs = [seq for seq in s if abs(len(seq) - np.mean(lengths)) < 2 * np.std(lengths)]\n",
    "std_dev = 1\n",
    "filtered_seqs = list(filter(lambda s: abs(len(s) - mean) < std_dev * std, all_seqs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make the relevant sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_df = pd.DataFrame(filtered_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_df.to_csv('data/sequence-data/1000-trial-terminals-1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_seqs = list(sequence_df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now you have to go from the raw sequences to the actual data for an RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "windowed_seqs = []\n",
    "for p in padded_seqs:\n",
    "    windows = build_rnn_sequences(list(p), sequence_df.shape[1])\n",
    "    windows = [w for w in windows if not all()]\n",
    "    windowed_seqs.extend(list(windows))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
